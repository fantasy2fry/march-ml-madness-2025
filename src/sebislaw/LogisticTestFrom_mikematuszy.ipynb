{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54132770-b49b-4040-8fff-e30c2e7ed62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import brier_score_loss\n",
    "import xgboost as xgb\n",
    "# import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c621418-b1e0-40e5-b74b-e065183ad174",
   "metadata": {},
   "outputs": [],
   "source": [
    "games = pd.read_csv('../../data/MRegularSeasonCompactResults.csv')\n",
    "gamesT = pd.read_csv('../../data/MNCAATourneyCompactResults.csv')\n",
    "games['TeamA'] = games[['WTeamID', 'LTeamID']].min(axis=1)\n",
    "games['TeamB'] = games[['WTeamID', 'LTeamID']].max(axis=1)\n",
    "gamesT['TeamA'] = gamesT[['WTeamID', 'LTeamID']].min(axis=1)\n",
    "gamesT['TeamB'] = gamesT[['WTeamID', 'LTeamID']].max(axis=1)\n",
    "def split_train_test_by_pair(games_df, n=1):\n",
    "    train_list = []\n",
    "    test_list = []\n",
    "    \n",
    "    grouped = games_df.groupby(['TeamA', 'TeamB'])\n",
    "    \n",
    "    for (teamA, teamB), group in grouped:\n",
    "        group_sorted = group.sort_values(['Season', 'DayNum'])\n",
    "        if len(group_sorted) > n:\n",
    "            train = group_sorted.iloc[:-n]\n",
    "            test = group_sorted.iloc[-n:]\n",
    "        else:\n",
    "            train = group_sorted.iloc[0:0]\n",
    "            test = group_sorted\n",
    "        \n",
    "        train_list.append(train)\n",
    "        test_list.append(test)\n",
    "    \n",
    "    train_set = pd.concat(train_list).reset_index(drop=True)\n",
    "    test_set = pd.concat(test_list).reset_index(drop=True)\n",
    "    \n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "287a4bc6-2423-4e87-903b-3c8f932efd86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (162629, 10)\n",
      "Test set shape: (355, 10)\n",
      "   Season  DayNum  WTeamID  WScore  LTeamID  LScore WLoc  NumOT  TeamA  TeamB\n",
      "0    2019     136     1246      79     1101      44    N      0   1101   1246\n",
      "1    2021     138     1101      53     1400      52    N      0   1101   1400\n",
      "2    2021     140     1417      67     1101      47    N      0   1101   1417\n",
      "3    2006     136     1228      78     1102      69    N      0   1102   1228\n",
      "4    2004     136     1314      63     1102      52    N      0   1102   1314\n"
     ]
    }
   ],
   "source": [
    "n = 1\n",
    "\n",
    "train_set, train_set2 = split_train_test_by_pair(games, n=n)\n",
    "test_set, test_set2 = split_train_test_by_pair(gamesT, n=n)\n",
    "\n",
    "print(\"Train set shape:\", train_set.shape)\n",
    "print(\"Test set shape:\", test_set.shape)\n",
    "print(test_set2.head())\n",
    "\n",
    "train_set = pd.concat([train_set, train_set2])\n",
    "test_set = pd.concat([test_set, test_set2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "151de007-79b4-4d01-ad4b-0e11708b6b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (191796, 10)\n",
      "Test set shape: (2518, 10)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97eb9008acb0413995c332a95592b35c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, description='Models:', max=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained models and their performance on the test set:\n",
      "Logistic Regression (CPU) - Training time: 3.75 sec, Brier Score: 0.2012\n"
     ]
    }
   ],
   "source": [
    "print(\"Train set shape:\", train_set.shape)\n",
    "print(\"Test set shape:\", test_set.shape)\n",
    "\n",
    "def create_features(df):\n",
    "    df = df.copy()\n",
    "    df['Outcome'] = (df['WTeamID'] == df['TeamA']).astype(int)\n",
    "    X = df[['TeamA', 'TeamB']].astype(str)\n",
    "    y = df['Outcome']\n",
    "    X_encoded = pd.get_dummies(X, columns=['TeamA', 'TeamB'])\n",
    "    return X_encoded, y\n",
    "\n",
    "X_train, y_train = create_features(train_set)\n",
    "X_test, y_test = create_features(test_set)\n",
    "\n",
    "X_train, X_test = X_train.align(X_test, join='left', axis=1, fill_value=0)\n",
    "\n",
    "models = {\n",
    "    # 'XGBoost (GPU)': xgb.XGBClassifier(tree_method='gpu_hist', use_label_encoder=False, eval_metric='logloss'),\n",
    "    # 'LightGBM (GPU)': lgb.LGBMClassifier(device='gpu'),\n",
    "    'Logistic Regression (CPU)': LogisticRegression(max_iter=1000),\n",
    "}\n",
    "\n",
    "bootstrap_threshold = 200 \n",
    "bootstrap_factor = 3\n",
    "\n",
    "progress = widgets.IntProgress(value=0, min=0, max=len(models), description='Models:')\n",
    "display(progress)\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    if len(X_train) < bootstrap_threshold:\n",
    "        X_train_boot = X_train.sample(n=bootstrap_factor * len(X_train), replace=True, random_state=42)\n",
    "        y_train_boot = y_train.loc[X_train_boot.index]\n",
    "        X_to_train = X_train_boot\n",
    "        y_to_train = y_train_boot\n",
    "    else:\n",
    "        X_to_train = X_train\n",
    "        y_to_train = y_train\n",
    "\n",
    "    start_time = time.time()\n",
    "    model.fit(X_to_train, y_to_train)\n",
    "    training_time = time.time() - start_time\n",
    "\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        y_pred_proba = model.decision_function(X_test)\n",
    "        y_pred_proba = 1 / (1 + np.exp(-y_pred_proba))\n",
    "        \n",
    "    brier = brier_score_loss(y_test, y_pred_proba)\n",
    "    \n",
    "    results[name] = {\n",
    "         'model': model,\n",
    "         'training_time': training_time,\n",
    "         'brier_score': brier,\n",
    "         'y_pred_proba': y_pred_proba\n",
    "    }\n",
    "    \n",
    "    progress.value += 1\n",
    "\n",
    "progress.layout.visibility = 'hidden'\n",
    "\n",
    "print(\"Trained models and their performance on the test set:\")\n",
    "for name, res in results.items():\n",
    "    print(f\"{name} - Training time: {res['training_time']:.2f} sec, Brier Score: {res['brier_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2550c73-03df-46e1-bd91-a2886766575c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
